{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c6ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from opencv-python) (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (2.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: networkx in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 489 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==2.7.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: numpy in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: filelock in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from torch==2.7.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kevinirungu/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.22.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 📦 Step 0: Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Install OpenCV if not already installed\n",
    "%pip install opencv-python\n",
    "# Install PyTorch if not already installed\n",
    "%pip install torch\n",
    "# Install torchvision if not already installed\n",
    "%pip install torchvision\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4ee32",
   "metadata": {},
   "source": [
    "# 🎮 Step 0: Data Collection\n",
    "This section allows the robot car to be driven using a gamepad. During this time, images are recorded along with throttle and steering inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acd914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pygame\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp39-cp39-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[K     |                                | 30 kB 698 kB/s eta 0:00:18  Downloading pygame-2.6.1-cp39-cp39-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 652 kB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 652 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n",
      "Successfully installed pygame-2.6.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No joystick connected!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ensure a joystick is connected\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pygame\u001b[38;5;241m.\u001b[39mjoystick\u001b[38;5;241m.\u001b[39mget_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo joystick connected!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m joystick \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mjoystick\u001b[38;5;241m.\u001b[39mJoystick(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m joystick\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[0;31mException\u001b[0m: No joystick connected!"
     ]
    }
   ],
   "source": [
    "# 🎮 Step 0: Data Collection\n",
    "%pip install pygame\n",
    "import pygame\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize pygame for gamepad control\n",
    "pygame.init()\n",
    "pygame.joystick.init()\n",
    "\n",
    "# Ensure a joystick is connected\n",
    "if pygame.joystick.get_count() == 0:\n",
    "    print('No joystick connected! Please connect a joystick and try again.')\n",
    "    pygame.quit()\n",
    "    exit()\n",
    "\n",
    "joystick = pygame.joystick.Joystick(0)\n",
    "joystick.init()\n",
    "\n",
    "# Create a directory for images\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Start data collection\n",
    "running = True\n",
    "data = []\n",
    "print('Press START button to begin recording and STOP button to end.')\n",
    "\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.JOYBUTTONDOWN:\n",
    "            if joystick.get_button(7):  # START button\n",
    "                print('Recording started...')\n",
    "                recording = True\n",
    "            elif joystick.get_button(6):  # BACK/STOP button\n",
    "                print('Recording stopped.')\n",
    "                running = False\n",
    "\n",
    "    if recording:\n",
    "        # Capture joystick inputs\n",
    "        steering = joystick.get_axis(0)  # Left stick horizontal axis\n",
    "        throttle = joystick.get_axis(1)  # Left stick vertical axis\n",
    "\n",
    "        # Capture image from camera\n",
    "        ret, frame = cv2.VideoCapture(0).read()\n",
    "        if ret:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S%f')\n",
    "            img_filename = f'{timestamp}.jpg'\n",
    "            img_path = os.path.join(DATA_DIR, img_filename)\n",
    "            cv2.imwrite(img_path, frame)\n",
    "\n",
    "            # Append data\n",
    "            data.append({'filename': img_filename, 'steering': steering, 'throttle': throttle})\n",
    "\n",
    "# Save data to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f'Data saved to {CSV_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6316b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Step 1: Settings\n",
    "import os  # Ensure os is imported\n",
    "DATA_DIR = \"data_logs\"\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"log.csv\")\n",
    "MODEL_PATH = \"drive_model.pth\"\n",
    "IMG_WIDTH, IMG_HEIGHT = 160, 120\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72fb069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename  steering  throttle\n",
       "0  img1.jpg       0.1       0.5\n",
       "1  img2.jpg      -0.2       0.6\n",
       "2  img3.jpg       0.0       0.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🗃️ Step 2: Load & Preview Data\n",
    "# Ensure the CSV file exists\n",
    "if not os.path.exists(CSV_PATH):\n",
    "\tprint(f'File not found: {CSV_PATH}. Creating a sample CSV file...')\n",
    "\tos.makedirs(DATA_DIR, exist_ok=True)\n",
    "\tsample_data = {\n",
    "\t\t'filename': ['img1.jpg', 'img2.jpg', 'img3.jpg'],\n",
    "\t\t'steering': [0.1, -0.2, 0.0],\n",
    "\t\t'throttle': [0.5, 0.6, 0.4]\n",
    "\t}\n",
    "\tsample_df = pd.DataFrame(sample_data)\n",
    "\tsample_df.to_csv(CSV_PATH, index=False)\n",
    "\tprint(f'Sample CSV created at {CSV_PATH}')\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b6579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: data_logs/log.csv. Creating a sample CSV file...\n",
      "Sample CSV created at data_logs/log.csv\n"
     ]
    }
   ],
   "source": [
    "# 🛠️ Step 2.1: Handle Missing CSV\n",
    "import os\n",
    "import pandas as pd\n",
    "# Check if the CSV file exists\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    print(f'File not found: {CSV_PATH}. Creating a sample CSV file...')\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    sample_data = {\n",
    "        'filename': ['img1.jpg', 'img2.jpg', 'img3.jpg'],\n",
    "        'steering': [0.1, -0.2, 0.0],\n",
    "        'throttle': [0.5, 0.6, 0.4]\n",
    "    }\n",
    "    sample_df = pd.DataFrame(sample_data)\n",
    "    sample_df.to_csv(CSV_PATH, index=False)\n",
    "    print(f'Sample CSV created at {CSV_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01ab35e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image not found: data_logs/img1.jpg\n",
      "Skipping index 10 as it is out-of-bounds.\n",
      "Skipping index 20 as it is out-of-bounds.\n",
      "Skipping index 30 as it is out-of-bounds.\n",
      "Skipping index 40 as it is out-of-bounds.\n",
      "Skipping index 50 as it is out-of-bounds.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 👁️ Step 3: Visualize driving scenarios\n",
    "import matplotlib.pyplot as plt  # Ensure plt is imported\n",
    "import cv2  # Ensure cv2 is imported\n",
    "import numpy as np  # Import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(6):\n",
    "    row_index = i * 10\n",
    "    if row_index >= len(df):\n",
    "        print(f\"Skipping index {row_index} as it is out-of-bounds.\")\n",
    "        continue\n",
    "    row = df.iloc[row_index]\n",
    "    img_path = os.path.join(DATA_DIR, row[\"filename\"])\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "        img = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)  # Placeholder black image\n",
    "    else:\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"S:{row['steering']:.2f}\\nT:{row['throttle']:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "511a0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image not found: data_logs/img1.jpg. Skipping.\n",
      "Skipping index 10 as it is out-of-bounds.\n",
      "Skipping index 20 as it is out-of-bounds.\n",
      "Skipping index 30 as it is out-of-bounds.\n",
      "Skipping index 40 as it is out-of-bounds.\n",
      "Skipping index 50 as it is out-of-bounds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🛠️ Step 3.1: Handle Out-of-Bounds Indexing\n",
    "plt.figure(figsize=(12, 4))\n",
    "num_rows = len(df)\n",
    "for i in range(6):\n",
    "    row_index = i * 10\n",
    "    if row_index >= num_rows:\n",
    "        print(f\"Skipping index {row_index} as it is out-of-bounds.\")\n",
    "        continue\n",
    "    row = df.iloc[row_index]\n",
    "    img_path = os.path.join(DATA_DIR, row[\"filename\"])\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image not found: {img_path}. Skipping.\")\n",
    "        continue\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"S:{row['steering']:.2f}\\nT:{row['throttle']:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f26721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Step 4: Dataset class\n",
    "from torch.utils.data import Dataset  # Import Dataset\n",
    "\n",
    "class DriveDataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None):\n",
    "        self.df = df\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.root, row[\"filename\"])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor([row[\"steering\"], row[\"throttle\"]], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a707308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📐 Step 5: Transforms + DataLoader\n",
    "from torchvision import transforms  # Import transforms\n",
    "from torch.utils.data import DataLoader  # Import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "dataset = DriveDataset(df, DATA_DIR, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de67aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Step 6: Define DriveNet\n",
    "import torch.nn as nn  # Import nn module\n",
    "\n",
    "class DriveNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5, stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2), nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 13 * 18, 100), nn.ReLU(),\n",
    "            nn.Linear(100, 2)  # [steering, throttle]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8702aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1584.646] global loadsave.cpp:268 findDecoder imread_('data_logs/img3.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      9\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     11\u001b[0m         valid_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m         valid_labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36mDriveDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m---> 17\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (IMG_WIDTH, IMG_HEIGHT))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Step 7: Train Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DriveNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Use torch.optim explicitly\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    for images, labels in loader:\n",
    "        valid_images = []\n",
    "        valid_labels = []\n",
    "        for img, lbl in zip(images, labels):\n",
    "            if img is None or not isinstance(img, torch.Tensor) or img.numel() == 0:  # Check for empty or invalid image\n",
    "                print(\"Skipping invalid image\")\n",
    "                continue\n",
    "            img_path = os.path.join(DATA_DIR, lbl[\"filename\"])  # Ensure the image path is correct\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Image not found: {img_path}. Skipping.\")\n",
    "                continue\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None or img.size == 0:  # Check if the image was successfully loaded\n",
    "                print(f\"Failed to load image: {img_path}. Skipping.\")\n",
    "                continue\n",
    "            valid_images.append(img)\n",
    "            valid_labels.append(lbl)\n",
    "\n",
    "        if not valid_images:\n",
    "            print(\"No valid images in this batch. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        valid_images = torch.stack(valid_images).to(device)\n",
    "        valid_labels = torch.stack(valid_labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(valid_images)\n",
    "        loss = criterion(outputs, valid_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b51f500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Step 8: Plot Training Loss\n",
    "plt.plot(losses, marker='o')\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f856c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 50 is out-of-bounds for the dataframe with 3 rows.\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Step 9: Test Prediction\n",
    "model.eval()\n",
    "if 50 < len(df):\n",
    "    test_img_path = os.path.join(DATA_DIR, df.iloc[50][\"filename\"])\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    input_tensor = transform(img_resized).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_tensor)[0].cpu().numpy()\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Predicted - Steering: {pred[0]:.2f}, Throttle: {pred[1]:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Index 50 is out-of-bounds for the dataframe with {len(df)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e707bc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as: drive_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 💾 Step 10: Save Model\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"✅ Model saved as: {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
